{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGA DE LIBRERIAS\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import json\n",
    "import numpy as np \n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LECTURA DE DATOS\n",
    "train_data_zip = '../files/input/train_data.csv.zip'\n",
    "test_data_zip = '../files/input/test_data.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCOMPRIMIR ARCHIVOS \n",
    "train_data = pd.read_csv(train_data_zip, index_col=False, compression='zip')\n",
    "test_data = pd.read_csv(test_data_zip, index_col=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1.\n",
    "# Realice la limpieza de los datasets:\n",
    "# - Renombre la columna \"default payment next month\" a \"default\".\n",
    "# - Remueva la columna \"ID\".\n",
    "# - Elimine los registros con informacion no disponible.\n",
    "# - Para la columna EDUCATION, valores > 4 indican niveles superiores\n",
    "#   de educación, agrupe estos valores en la categoría \"others\".\n",
    "\n",
    "def clean_data(data_df):\n",
    "    \n",
    "    df=data_df.copy()\n",
    "    df=df.rename(columns={'default payment next month': 'default'})\n",
    "    df=df.drop(columns='ID')\n",
    "    df['EDUCATION'] = df['EDUCATION'].replace(0, np.nan)\n",
    "    df['MARRIAGE'] = df['MARRIAGE'].replace(0, np.nan)\n",
    "    df=df.dropna()\n",
    "    df.loc[df['EDUCATION'] > 4, 'EDUCATION'] = 4\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = clean_data(train_data)\n",
    "test_data = clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test.\n",
    "x_train = train_data.drop(columns='default', axis=1)\n",
    "y_train = train_data['default']\n",
    "\n",
    "x_test = test_data.drop(columns='default', axis=1)\n",
    "y_test = test_data['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Descompone la matriz de entrada usando PCA. El PCA usa todas las componentes.\n",
    "# - Estandariza la matriz de entrada.\n",
    "# - Selecciona las K columnas mas relevantes de la matrix de entrada.\n",
    "# - Ajusta una maquina de vectores de soporte (svm).\n",
    "\n",
    "def create_pipeline(df):\n",
    "    cat_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "    num_features = [col for col in df.columns if col not in cat_features]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),   \n",
    "            ('num', StandardScaler(), num_features), \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('pca', PCA()),\n",
    "            ('select_k_best', SelectKBest(f_classif)),\n",
    "            ('model', SVC()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use la función de precision\n",
    "# balanceada para medir la precisión del modelo.\n",
    "\n",
    "def optimize_hyperparameters(pipeline, x_train, y_train):\n",
    "    param_grid = {\n",
    "        'pca__n_components': [21],\n",
    "        'select_k_best__k': [12],\n",
    "        'model__C': [0.8],\n",
    "        'model__kernel': ['rbf'],\n",
    "         'model__gamma': [0.1],\n",
    "    }\n",
    "    grid_search=GridSearchCV(pipeline, param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1, verbose=2 )\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Tiempo de optimizacion parametros: 87.73 seconds\n",
      "{'model__C': 0.8, 'model__gamma': 0.1, 'model__kernel': 'rbf', 'pca__n_components': 21, 'select_k_best__k': 12}\n"
     ]
    }
   ],
   "source": [
    "# Optimizar los hiperparametros\n",
    "start = time.time()\n",
    "model = optimize_hyperparameters(pipeline, x_train, y_train)\n",
    "end = time.time()\n",
    "print(f'Tiempo de optimizacion parametros: {end - start:.2f} seconds')\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip.\n",
    "\n",
    "def save_model(model):\n",
    "    \n",
    "    if not os.path.exists('../files/models'):\n",
    "        os.makedirs('../files/models')\n",
    "    \n",
    "    with gzip.open('../files/models/model.pkl.gz', 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6.\n",
    "# Calcule las metricas de precision, precision balanceada, recall,\n",
    "# y f1-score para los conjuntos de entrenamiento y prueba.\n",
    "# Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "# del archivo es un diccionario con las metricas de un modelo.\n",
    "# Este diccionario tiene un campo para indicar si es el conjunto\n",
    "# de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "# {'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}\n",
    "\n",
    "def calculate_metrics(model, x_train, y_train, x_test, y_test):\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    metrics_train = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'train',\n",
    "        'precision': float(round(precision_score(y_train, y_train_pred),4)),\n",
    "        'balanced_accuracy': float(round(balanced_accuracy_score(y_train, y_train_pred),4)),\n",
    "        'recall': float(round(recall_score(y_train, y_train_pred),4)),\n",
    "        'f1_score': float(round(f1_score(y_train, y_train_pred),4))\n",
    "    }\n",
    "\n",
    "    metrics_test = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'test',\n",
    "        'precision': float(round(precision_score(y_test, y_test_pred),4)),\n",
    "        'balanced_accuracy': float(round(balanced_accuracy_score(y_test, y_test_pred),4)),\n",
    "        'recall': float(round(recall_score(y_test, y_test_pred),4)),\n",
    "        'f1_score': float(round(f1_score(y_test, y_test_pred),4))\n",
    "    }\n",
    "\n",
    "    print(metrics_train)\n",
    "    print(metrics_test)\n",
    "\n",
    "    return metrics_train, metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'metrics', 'dataset': 'train', 'precision': 0.7006, 'balanced_accuracy': 0.6624, 'recall': 0.371, 'f1_score': 0.4851}\n",
      "{'type': 'metrics', 'dataset': 'test', 'precision': 0.675, 'balanced_accuracy': 0.6669, 'recall': 0.3835, 'f1_score': 0.4891}\n"
     ]
    }
   ],
   "source": [
    "metrics_train, metrics_test = calculate_metrics(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7.\n",
    "# Calcule las matrices de confusion para los conjuntos de entrenamiento y\n",
    "# prueba. Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "# del archivo es un diccionario con las metricas de un modelo.\n",
    "# de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    "# {'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}\n",
    "#\n",
    "def calculate_confusion_matrix(model, x_train, y_train, x_test, y_test):\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    cm_matrix_train = {\n",
    "        'type': 'cm_matrix',\n",
    "        'dataset': 'train',\n",
    "        'true_0': {\"predicted_0\": int(cm_train[0, 0]), \"predicted_1\": int(cm_train[0, 1])},\n",
    "        'true_1': {\"predicted_0\": int(cm_train[1, 0]), \"predicted_1\": int(cm_train[1, 1])}\n",
    "    }\n",
    "\n",
    "    cm_matrix_test = {\n",
    "        'type': 'cm_matrix',\n",
    "        'dataset': 'test',\n",
    "        'true_0': {\"predicted_0\": int(cm_test[0, 0]), \"predicted_1\": int(cm_test[0, 1])},\n",
    "        'true_1': {\"predicted_0\": int(cm_test[1, 0]), \"predicted_1\": int(cm_test[1, 1])}\n",
    "    }\n",
    "\n",
    "    return cm_matrix_train, cm_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix_train, cm_matrix_test = calculate_confusion_matrix(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'cm_matrix',\n",
       " 'dataset': 'train',\n",
       " 'true_0': {'predicted_0': 15479, 'predicted_1': 749},\n",
       " 'true_1': {'predicted_0': 2972, 'predicted_1': 1753}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar los parametros en carpeta output\n",
    "def save_metrics(metrics_train, metrics_test, cm_matrix_train, cm_matrix_test):\n",
    "    \n",
    "    if not os.path.exists('../files/output'):\n",
    "        os.makedirs('../files/output')\n",
    "    \n",
    "    metrics = [metrics_train, metrics_test, cm_matrix_train, cm_matrix_test]\n",
    "    pd.DataFrame(metrics).to_json('../files/output/metrics.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics(metrics_train, metrics_test, cm_matrix_train, cm_matrix_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
